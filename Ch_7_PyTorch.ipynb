{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Ethan Herron 3-4-2020\n",
    "\n",
    "This is my jupyter notebook for the book Deep Learning from Scratch by Seth Weidman. I will be following along with all of the code, and adding insights or questions I have along the way in these markdown cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "from pytorch.layers import PyTorchLayer, DenseLayer\n",
    "from pytorch.model import PyTorchModel\n",
    "from pytorch.train import PyTorchTrainer\n",
    "from pytorch.preprocessor import ConvNetPreprocessor\n",
    "from pytorch.utils import assert_dim, permute_data\n",
    "\n",
    "torch.manual_seed(20190325);\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "features = boston.feature_names\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "data = s.fit_transform(data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=80718)\n",
    "\n",
    "y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = Tensor(X_train), Tensor(X_test), Tensor(y_train), Tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Boston model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BostonModel(PyTorchModel):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 hidden_size: int = 13,\n",
    "                 hidden_dropout: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.dense1 = DenseLayer(13, hidden_size,\n",
    "                                  activation=nn.Tanh(),\n",
    "                                  dropout = hidden_dropout)\n",
    "        self.dense2 = DenseLayer(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x: Tensor,\n",
    "                inference: bool = False) -> Tensor:\n",
    "        \n",
    "        assert_dim(x, 2)\n",
    "        \n",
    "        assert x.shape[1] == 13\n",
    "        \n",
    "        x = self.dense1(x, inference)\n",
    "        return self.dense2(x, inference),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model -> optimizer -> loss\n",
    "pytorch_boston_model = BostonModel(hidden_size=13, hidden_dropout=0.8)\n",
    "optimizer = optim.SGD(pytorch_boston_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\herro\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after 1 epochs was 437.0394592285156\n",
      "The loss after 11 epochs was 25.67037010192871\n",
      "The loss after 21 epochs was 21.64051055908203\n",
      "The loss after 31 epochs was 19.2457275390625\n",
      "The loss after 41 epochs was 19.330734252929688\n",
      "The loss after 51 epochs was 17.945085525512695\n",
      "The loss after 61 epochs was 18.49933433532715\n",
      "The loss after 71 epochs was 18.45086097717285\n",
      "The loss after 81 epochs was 17.083316802978516\n",
      "The loss after 91 epochs was 16.426305770874023\n"
     ]
    }
   ],
   "source": [
    "trainer = PyTorchTrainer(pytorch_boston_model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            epochs=100,\n",
    "            eval_every=10,\n",
    "            final_lr_exp = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.732015609741211"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.pow(pytorch_boston_model(X_test, inference=True)[0] - y_test, 2)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pytorch_boston_model(X_test)[0].view(-1)\n",
    "test_actual = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test_pred.detach().numpy()\n",
    "test_actual = test_actual.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2ed67221080>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(test_pred, test_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs using PyTorch\n",
    "The first example will be using DataLoaders and the second will be without DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1305,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/data.html\n",
    "train_dataset = MNIST(root='/mnist.pkl',\n",
    "                      train=True,\n",
    "                      download=True,\n",
    "                      transform=img_transforms)\n",
    "\n",
    "test_dataset = MNIST(root='/mnist.pkl',\n",
    "                     train=False,\n",
    "                     download=True,\n",
    "                     transform=img_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=60, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=60, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(PyTorchLayer):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 filter_size: int,\n",
    "                 activation: nn.Module = None,\n",
    "                 dropout: float = 1.0,\n",
    "                 flatten: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, filter_size, \n",
    "                              padding=filter_size // 2)\n",
    "        self.activation = activation\n",
    "        self.flatten = flatten\n",
    "        if dropout < 1.0:\n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x = self.conv(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        if self.flatten:\n",
    "            x = x.view(x.shape[0], x.shape[1] * x.shape[2] * x.shape[3])\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x)            \n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_ConvNet(PyTorchModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvLayer(1, 14, 5, activation=nn.Tanh(),\n",
    "                               dropout=0.8)\n",
    "        self.conv2 = ConvLayer(14, 7, 5, activation=nn.Tanh(), flatten=True,\n",
    "                               dropout=0.8)\n",
    "        self.dense1 = DenseLayer(28 * 28 * 7, 32, activation=nn.Tanh(),\n",
    "                                 dropout=0.8)\n",
    "        self.dense2 = DenseLayer(32, 10)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        assert_dim(x, 4)\n",
    "            \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_ConvNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing using only DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after 0 epochs was 0.1188\n"
     ]
    }
   ],
   "source": [
    "trainer = PyTorchTrainer(model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(train_dataloader = train_loader,        \n",
    "            test_dataloader = test_loader,\n",
    "            epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy using only DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model):\n",
    "    model.eval()\n",
    "    accuracies = []\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        output = model(X_batch)[0]\n",
    "        accuracy_batch = (torch.max(output, dim=1)[1] == y_batch).type(torch.float32).mean().item()\n",
    "        accuracies.append(accuracy_batch)\n",
    "    return torch.Tensor(accuracies).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9658681750297546"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without using DataLoader\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = ((train_dataset.data.type(torch.float32).unsqueeze(3).permute(0, 3, 1, 2) / 255.0) - 0.1305) / 0.3081\n",
    "mnist_test = ((test_dataset.data.type(torch.float32).unsqueeze(3).permute(0, 3, 1, 2) / 255.0) - 0.1305) / 0.3081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.4236), tensor(2.8221), tensor(-0.4236), tensor(2.8221))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.min(), mnist_train.max(), mnist_test.min(), mnist_test.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after 1 epochs was 0.09398534893989563\n"
     ]
    }
   ],
   "source": [
    "trainer = PyTorchTrainer(model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(X_train=mnist_train, y_train=train_dataset.targets,\n",
    "            X_test=mnist_test, y_test=test_dataset.targets,\n",
    "             epochs=1,\n",
    "             eval_every=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_no_dataloader(model, mnist_test):\n",
    "    model.eval()\n",
    "    output = model(mnist_test)[0]\n",
    "    return (torch.max(output, dim=1)[1] == test_dataset.test_labels).type(torch.float32).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\herro\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9710000157356262"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_no_dataloader(model, mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "### LSTMLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLayer(PyTorchLayer):\n",
    "    def __init__(self,\n",
    "                 sequence_length: int,\n",
    "                 input_size: int,\n",
    "                 hidden_size: int,\n",
    "                 output_size: int,\n",
    "                 dropout: float = 1.0) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.h_init = torch.zeros((1, hidden_size))\n",
    "        self.c_init = torch.zeros((1, hidden_size))\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = DenseLayer(hidden_size, output_size)\n",
    "        if dropout < 1.0:\n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "    def _transform_hidden_batch(self, hidden: Tensor,\n",
    "                                batch_size: int,\n",
    "                                before_layer: bool) -> Tensor:\n",
    "        \n",
    "        if before_layer:\n",
    "            return (hidden\n",
    "                    .repeat(batch_size, 1)\n",
    "                    .view(batch_size, 1, self.hidden_size)\n",
    "                    .permute(1,0,2))\n",
    "        else:\n",
    "            return (hidden\n",
    "                    .permute(1,0,2)\n",
    "                    .mean(dim=0))         \n",
    "    \n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        h_layer = self._transform_hidden_batch(self.h_init, batch_size, before_layer=True)\n",
    "        c_layer = self._transform_hidden_batch(self.c_init, batch_size, before_layer=True)\n",
    "        \n",
    "        x, (h_out, c_out) = self.lstm(x, (h_layer, c_layer))\n",
    "        \n",
    "        self.h_init, self.c_init = (\n",
    "            self._transform_hidden_batch(h_out, batch_size, before_layer=False).detach(),\n",
    "            self._transform_hidden_batch(c_out, batch_size, before_layer=False).detach()\n",
    "        )\n",
    "\n",
    "        x = self.fc(x)\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x) \n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 25, 128])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay = LSTMLayer(sequence_length=25,\n",
    "                input_size=62,\n",
    "                hidden_size=100,\n",
    "                output_size=128)\n",
    "\n",
    "x = torch.randn(32, 25, 62)\n",
    "\n",
    "lay(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Character Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextCharacterModel(PyTorchModel):\n",
    "    def __init__(self,\n",
    "                 vocab_size: int,\n",
    "                 hidden_size: int = 256,\n",
    "                 sequence_length: int = 25):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # In this model, we have only one layer, with the same output size as input_size\n",
    "        self.lstm = LSTMLayer(self.sequence_length, self.vocab_size, hidden_size, self.vocab_size)\n",
    "\n",
    "    def forward(self,\n",
    "                inputs: Tensor):\n",
    "        assert_dim(inputs, 3) # batch_size, sequence_length, vocab_size\n",
    "\n",
    "        out = self.lstm(inputs)       \n",
    "        \n",
    "        return out.permute(0, 2, 1),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMTrainer(PyTorchTrainer):\n",
    "    def __init__(self,\n",
    "                 model: NextCharacterModel,\n",
    "                 optim: Optimizer,\n",
    "                 criterion: _Loss):\n",
    "        super().__init__(model, optim, criterion)\n",
    "        self.vocab_size = self.model.vocab_size\n",
    "        self.max_len = self.model.sequence_length\n",
    "        \n",
    "    def fit(self,\n",
    "            data: str,\n",
    "            epochs: int=10,\n",
    "            eval_every: int=1,\n",
    "            batch_size: int=32,\n",
    "            seed: int = 121718)-> None:\n",
    "        \n",
    "        self.data = data\n",
    "        self.train_data, self.test_data = self._train_test_split_text()\n",
    "        self.chars = list(set(self.data))\n",
    "        self.char_to_idx = {ch: i for i, ch in enumerate(self.chars)}\n",
    "        self.idx_to_char = {i: ch for i, ch in enumerate(self.chars)}\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        losses = deque(maxlen=50)\n",
    "        \n",
    "        for e in range(epochs):\n",
    "\n",
    "            batch_generator = self.generate_batches_next_char(batch_size)\n",
    "\n",
    "            for ii, (X_batch, y_batch) in enumerate(batch_generator):\n",
    "\n",
    "                self.optim.zero_grad()                \n",
    "                outputs = self.model(X_batch)[0]\n",
    "\n",
    "                loss = self.loss(outputs, y_batch)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                loss.backward()\n",
    "                \n",
    "                self.optim.step()\n",
    "                \n",
    "            if (e+1) % eval_every == 0:\n",
    "                \n",
    "                X_test, y_test = self.generate_test_data()\n",
    "            \n",
    "                test_preds = self.model.forward(X_test)[0]\n",
    "\n",
    "                loss = self.loss.forward(test_preds, y_test)\n",
    "                print(f\"Validation loss after {e+1} epochs is {loss.item():.3f}\")\n",
    "\n",
    "    def _train_test_split_text(self, pct=0.8) -> Tuple[str]:\n",
    "\n",
    "        n = len(self.data)\n",
    "        return self.data[:int(n * pct)], self.data[int(n * pct):]\n",
    "\n",
    "    def generate_batches_next_char(self,\n",
    "                                   batch_size: int) -> Tuple[Tensor]:\n",
    "        N = len(self.train_data)\n",
    "        # add batch size\n",
    "        for ii in range(0, N, batch_size):\n",
    "\n",
    "            features_tensors = []\n",
    "            target_indices = []\n",
    "\n",
    "            for char in range(batch_size):\n",
    "\n",
    "                features_str, target_str =\\\n",
    "                 self.train_data[ii+char:ii+char+self.max_len],\\\n",
    "                 self.train_data[ii+char+1:ii+char+self.max_len+1]\n",
    "\n",
    "                features_array = self._string_to_one_hot_array(features_str)\n",
    "                target_indices_seq = [self.char_to_idx[char] for char in target_str]\n",
    "\n",
    "                features_tensors.append(features_array)\n",
    "                target_indices.append(target_indices_seq)\n",
    "            if len(features_str) != len(target_str):\n",
    "                break\n",
    "            yield torch.stack(features_tensors), torch.LongTensor(target_indices)\n",
    "\n",
    "    def _string_to_one_hot_array(self, input_string: str) -> Tuple[Tensor]:\n",
    "\n",
    "        ind = [self.char_to_idx[ch] for ch in input_string]\n",
    "\n",
    "        array = self._one_hot_text_data(ind)\n",
    "\n",
    "        return array\n",
    "\n",
    "    def _one_hot_text_data(self,\n",
    "                           sequence: List):\n",
    "\n",
    "        sequence_length = len(sequence)\n",
    "        batch = torch.zeros(sequence_length, self.vocab_size)\n",
    "        for i in range(sequence_length):\n",
    "            batch[i, sequence[i]] = 1.0\n",
    "\n",
    "        return Tensor(batch)\n",
    "\n",
    "    def generate_test_data(self) -> Tuple[Tensor]:\n",
    "\n",
    "        features_str, target_str = self.test_data[:-1], self.test_data[1:]\n",
    "\n",
    "        X_tensors = []\n",
    "        y_tensors = []\n",
    "\n",
    "        N = len(self.test_data)\n",
    "\n",
    "        for start in range(0, N, self.max_len):\n",
    "\n",
    "            features_str, target_str =\\\n",
    "                self.test_data[start:start+self.max_len],\\\n",
    "                self.test_data[start+1:start+self.max_len+1]\n",
    "\n",
    "            if len(features_str) != len(target_str):\n",
    "                break\n",
    "            features_array = self._string_to_one_hot_array(features_str)\n",
    "            target_indices_seq = [self.char_to_idx[char] for char in target_str]\n",
    "\n",
    "            X_tensors.append(features_array)\n",
    "            y_tensors.append(torch.LongTensor(target_indices_seq))\n",
    "            \n",
    "        return torch.stack(X_tensors), torch.stack(y_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('/Users/herro/input.txt', 'r').read()\n",
    "vocab_size = len(set(data))\n",
    "model = NextCharacterModel(vocab_size, hidden_size=vocab_size, sequence_length=50)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,\n",
    "                             weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_trainer = LSTMTrainer(model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 1 epochs is 2.338\n"
     ]
    }
   ],
   "source": [
    "lstm_trainer.fit(data, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning with Autoencoder\n",
    "### DeconvLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeconvLayer(PyTorchLayer):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 filter_size: int,\n",
    "                 activation: nn.Module = None,\n",
    "                 dropout: float = 1.0,\n",
    "                 flatten: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.deconv = nn.ConvTranspose2d(in_channels, out_channels, filter_size,\n",
    "                                         padding=filter_size // 2)\n",
    "        self.activation = activation\n",
    "        self.flatten = flatten\n",
    "        if dropout < 1.0:\n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "            \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \n",
    "        x = self.deconv(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        if self.flatten:\n",
    "            x = x.view(x.shape[0], x.shape[1] * x.shape[2] * x.shape[3])\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(PyTorchModel):\n",
    "    def __init__(self,\n",
    "                 hidden_dim: int = 28):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.conv1 = ConvLayer(1, 14, 5, activation=nn.Tanh())\n",
    "        self.conv2 = ConvLayer(14, 7, 5, activation=nn.Tanh(), flatten=True)\n",
    "        \n",
    "        self.dense1 = DenseLayer(7 * 28 * 28, hidden_dim, activation=nn.Tanh())\n",
    "        self.dense2 = DenseLayer(hidden_dim, 7 * 28 * 28, activation=nn.Tanh())\n",
    "        \n",
    "        self.conv3 = ConvLayer(7, 14, 5, activation=nn.Tanh()) \n",
    "        self.conv4 = ConvLayer(14, 1, 5, activation=nn.Tanh())         \n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        assert_dim(x, 4)\n",
    "            \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "#         import pdb; pdb.set_trace()\n",
    "        encoding = self.dense1(x)\n",
    "        \n",
    "        x = self.dense2(encoding)\n",
    "        \n",
    "        x = x.view(-1, 7, 28, 28)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        return x, encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist_train\n",
    "X_test = mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_auto = (X_train - X_train.min()) / (X_train.max() - X_train.min()) * 2 - 1\n",
    "X_test_auto = (X_test - X_train.min()) / (X_train.max() - X_train.min()) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after 1 epochs was 0.06928424537181854\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(hidden_dim=28)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "trainer = PyTorchTrainer(model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(X_train_auto, X_train_auto,\n",
    "            X_test_auto, X_test_auto,\n",
    "            epochs=1,\n",
    "            batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 10976000000 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-0053fe380555>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreconstructed_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_representations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_auto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-72ea3af974cd>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-b2ee3bdb69ac>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 10976000000 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "reconstructed_images, image_representations = model(X_test_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(ax,\n",
    "                  t: Tensor):\n",
    "    n = t.detach().numpy()\n",
    "    ax.imshow(n.shape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(188292)\n",
    "a = np.random.randint(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[a].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,2)\n",
    "display_image(axarr[0], X_test[a])\n",
    "display_image(axarr[1], reconstructed_images[a])\n",
    "\n",
    "axarr[0].set_title(\"Original image\")\n",
    "axarr[1].set_title(\"Image reconstructed\\nfrom autoencoder\")\n",
    "\n",
    "axarr[0].axis('off')\n",
    "axarr[1].axis('off');\n",
    "\n",
    "# f.savefig(\"../../01_deep-learning-from-scratch/images/07_pytorch/03_autoencoder_example_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne_result = TSNE(n_components=2, random_state=20190405).fit_transform(image_representations.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tsne_df = pd.DataFrame({'tsne_dim_1': tsne_result[:,0],\n",
    "              'tsne_dim_2': tsne_result[:,1],\n",
    "              'category': test_dataset.targets})\n",
    "groups = tsne_df.groupby('category')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "ax.set_title('''10000 observations from MNIST test set, colored by their actual digit. \n",
    "Locations are the result of reducing the 28 values from hidden layer of the convolutional\n",
    "autoencoder - trained without labels - down to two dimensions using t-SNE.''')\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in groups:\n",
    "    ax.scatter(group['tsne_dim_1'], group['tsne_dim_2'], marker='o', label=name)\n",
    "ax.legend();\n",
    "# fig.savefig(\"../../01_deep-learning-from-scratch/images/07_pytorch/00_tsne.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
